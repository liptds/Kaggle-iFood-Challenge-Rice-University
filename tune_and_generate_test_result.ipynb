{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "This notebook help to determine some hyperparameters for acquiring the best test result and generate .csv for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imagDataset_test(Dataset):\n",
    "    # data set get image data \n",
    "    \"\"\"\n",
    "    Data set to import imag\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  root_dir, transform = None):\n",
    "        self.root_dir   = root_dir\n",
    "        self.transform  = transform\n",
    "        self.file_name = [f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f))]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_name)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if( torch.is_tensor(item)):\n",
    "            item = item.tolist()\n",
    "\n",
    "        img_name = os.path.join( self.root_dir, self.file_name[item])\n",
    "        #image = io.imread(img_name)\n",
    "        image = Image.open(img_name)\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        if(self.transform):\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {'image':image, 'label':item}\n",
    "        \n",
    "        return sample\n",
    "\n",
    "    def get_file_name(self):\n",
    "        return self.file_name\n",
    "\n",
    "\n",
    "\n",
    "def get_test_data(root,fig_size, batch_size):\n",
    "    # ensemble data loader\n",
    "    # use three data pre-processing methods \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "                transforms.Resize((300,300)),\n",
    "                transforms.CenterCrop(fig_size),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "    trans2 = transforms.Compose([\n",
    "                transforms.Resize((fig_size,fig_size)),\n",
    "                transforms.ToTensor(),\n",
    "                normalize])\n",
    "    trans3=transforms.Compose([               \n",
    "                transforms.RandomRotation(degrees=90),\n",
    "                transforms.RandomResizedCrop(fig_size,scale=(0.05, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize])\n",
    "    test_data = imagDataset_test(root, transform=trans)\n",
    "    test_data2= imagDataset_test(root, transform=trans2)\n",
    "    test_data3= imagDataset_test(root, transform=trans3)\n",
    "    test_name = test_data.get_file_name()\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_dataloader2 = DataLoader(test_data2, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_dataloader3 = DataLoader(test_data3, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    print(\"num of data\",len(test_data))\n",
    "    return [test_dataloader, test_dataloader2,test_dataloader3,test_name]\n",
    "\n",
    "\n",
    "\n",
    "class chain_model(nn.Module): # define the model here for load model \n",
    "    def __init__(self, pre_trained, num_classes):\n",
    "        super(chain_model, self).__init__()\n",
    "        self.pre_trained = pre_trained # pre trained model \n",
    "        \n",
    "        for param in self.pre_trained.parameters():\n",
    "            param.requires_grad = False # don't do gradient descent for bottom part \n",
    "                    \n",
    "        in_feature = self.pre_trained.fc.in_features\n",
    "        \n",
    "        feature_1 = 2000\n",
    "        feature_2 = 1000\n",
    "        feature_3 = num_classes\n",
    "        \n",
    "        self.pre_trained.fc = nn.Linear(in_feature, feature_1)\n",
    "        self.rl1 = nn.LeakyReLU()\n",
    "        self.fc1 = nn.Linear(feature_1, feature_2)\n",
    "        self.rl2 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(feature_2, feature_3)\n",
    "    \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pre_trained(x)\n",
    "        x = self.rl1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.rl2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x \n",
    "        \n",
    "        \n",
    "def load_model(path):\n",
    "    if( not os.path.isfile(path)):\n",
    "        print(\" model doesn't exist\")\n",
    "        return None\n",
    "    \n",
    "    check_point = torch.load(path)\n",
    "\n",
    "    model      = check_point['model']\n",
    "    print(\"load model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predict(test_data, test_data2,test_data3,test_file, model_ensemble,weight, device):\n",
    "    \"\"\"\n",
    "    test_data: data loader\n",
    "    test_data2:\n",
    "    test_data3:\n",
    "    data loader with different data pre-processing methods \n",
    "    \n",
    "    test_file: list of file name \n",
    "    model ensemble: list of model to do ensemble \n",
    "    weight: weight for each ensemble\n",
    "    \n",
    "    \"\"\"\n",
    "    soft_max =nn.Softmax(dim=1)\n",
    "    for model in model_ensemble:\n",
    "        model.eval() \n",
    "    with torch.no_grad():\n",
    "        name_list = []\n",
    "        class_list = []\n",
    "        it2=iter(test_data2)\n",
    "        it3=iter(test_data3)\n",
    "        for i_batch, sample_batched in enumerate(test_data):\n",
    "            data2=next(it2)\n",
    "            data3=next(it3)\n",
    "            x = sample_batched['image'].to(device=device, dtype=torch.float32)\n",
    "            x2 =data2['image'].to(device=device, dtype=torch.float)\n",
    "            x3 =data3['image'].to(device=device, dtype=torch.float)\n",
    "            ind = sample_batched['label'].to(device=device, dtype=torch.long) \n",
    "            # read data by different data loader\n",
    "            \n",
    "            score_1 = weight[0] * soft_max(model_ensemble[0](x))[:,0:251]\n",
    "            score_2 = weight[0] * soft_max(model_ensemble[0](x2))[:,0:251]\n",
    "            score_3 = weight[0] * soft_max(model_ensemble[0](x3))[:,0:251]\n",
    "            scores  = score_1 * 0.75 + score_2 * 0.425 + score_3 * 0.25 # weighted average for each output \n",
    "            \n",
    "            for i in range(1,len(model_ensemble)): # weighted average for each model\n",
    "                score_1 = weight[i] * soft_max(model_ensemble[i](x))[:,0:251]\n",
    "                score_2 = weight[i] * soft_max(model_ensemble[i](x2))[:,0:251]\n",
    "                score_3 = weight[i] * soft_max(model_ensemble[i](x3))[:,0:251]\n",
    "                scores  += score_1 * 0.75 + score_2 * 0.425 + score_3 * 0.25 # weighted average of each output \n",
    "            # Ensemble method for x1,x2,x3 input. Ensemble method for models \n",
    "            \n",
    "            \n",
    "            _,preds=scores.topk(3,1) \n",
    " \n",
    "            name_list = name_list + [test_file[i] for i in ind]\n",
    "            class_list = class_list + preds.tolist()\n",
    "\n",
    "            ans=np.hstack((np.asarray(name_list).reshape((len(name_list),1)),np.asarray(class_list)))\n",
    "            # get top three prediction \n",
    "            \n",
    "            if( i_batch %50 == 0):\n",
    "                print(\"ibatch = \",i_batch, len(class_list), len(name_list))\n",
    "        df=pd.DataFrame(ans)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "num of data 28377\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fig_size = 224\n",
    "batch_size = 16\n",
    "path_test_data = '../input/project-ifood/test_set/test_set' # path to the test set \n",
    "test1,test2,test3, filename =  get_test_data(path_test_data,fig_size, batch_size) # read model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/model-ensemble/res101_16\n",
      "../input/model-ensemble/res101_16\n",
      "load model\n",
      "../input/model-ensemble/res152\n",
      "../input/model-ensemble/res152\n",
      "load model\n",
      "../input/res152net3fc/wideres50fc3\n",
      "../input/res152net3fc/wideres50fc3\n",
      "load model\n",
      "../input/res152net3fc/res152fc3\n",
      "../input/res152net3fc/res152fc3\n",
      "load model\n",
      "../input/model-ensemble/resnext_13_model_only/model_only_13\n",
      "../input/model-ensemble/resnext_13_model_only/model_only_13\n"
     ]
    }
   ],
   "source": [
    "path_list = [\"../input/model-ensemble/res101_16\", \"../input/model-ensemble/res152\",\n",
    "              \"../input/res152net3fc/wideres50fc3\", \"../input/res152net3fc/res152fc3\",\n",
    "             '../input/model-ensemble/resnext_13_model_only/model_only_13' ]\n",
    "# list of path of each model \n",
    "weight =  [3,3,3,2,2]\n",
    "# weight of each model \n",
    "\n",
    "model_list = []\n",
    "for path_model in path_list:\n",
    "    model_list.append(load_model(path_model)[0] )\n",
    "# read the model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibatch =  0 16 16\n",
      "ibatch =  50 816 816\n",
      "ibatch =  100 1616 1616\n",
      "ibatch =  150 2416 2416\n",
      "ibatch =  200 3216 3216\n",
      "ibatch =  250 4016 4016\n",
      "ibatch =  300 4816 4816\n",
      "ibatch =  350 5616 5616\n",
      "ibatch =  400 6416 6416\n",
      "ibatch =  450 7216 7216\n",
      "ibatch =  500 8016 8016\n",
      "ibatch =  550 8816 8816\n",
      "ibatch =  600 9616 9616\n",
      "ibatch =  650 10416 10416\n",
      "ibatch =  700 11216 11216\n",
      "ibatch =  750 12016 12016\n",
      "ibatch =  800 12816 12816\n",
      "ibatch =  850 13616 13616\n",
      "ibatch =  900 14416 14416\n",
      "ibatch =  950 15216 15216\n",
      "ibatch =  1000 16016 16016\n",
      "ibatch =  1050 16816 16816\n",
      "ibatch =  1100 17616 17616\n",
      "ibatch =  1150 18416 18416\n",
      "ibatch =  1200 19216 19216\n",
      "ibatch =  1250 20016 20016\n",
      "ibatch =  1300 20816 20816\n",
      "ibatch =  1350 21616 21616\n",
      "ibatch =  1400 22416 22416\n",
      "ibatch =  1450 23216 23216\n",
      "ibatch =  1500 24016 24016\n",
      "ibatch =  1550 24816 24816\n",
      "ibatch =  1600 25616 25616\n",
      "ibatch =  1650 26416 26416\n",
      "ibatch =  1700 27216 27216\n",
      "ibatch =  1750 28016 28016\n"
     ]
    }
   ],
   "source": [
    "path_save = '../working/ensemble_4.csv'  # save the prediction to this path \n",
    "df = print_predict(test1,test2,test3,filename, model_list, weight,device) # get prediction \n",
    "df.columns = ['img_name','label1', 'label2', 'label3' ]\n",
    "df['label']=df.apply(lambda x:' '.join(str(x) for x in x[1:]),axis=1)\n",
    "df=df.loc[:,['img_name','label']]\n",
    "df.to_csv(path_save, index=False) # save "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
